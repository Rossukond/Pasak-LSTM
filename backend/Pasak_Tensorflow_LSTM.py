# -*- coding: utf-8 -*-
"""Copy of LSTM V.3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hv6D-9YKWBAgLOW_rR2iFjEnR26yYxXC
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import json
from sklearn.metrics import mean_squared_error
from tensorflow.keras.callbacks import Callback
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from flask import Flask, request, jsonify
from flask_cors import CORS


app = Flask(__name__)
CORS(app, origins="http://localhost:5173", supports_credentials=True)
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

def load_data(file_obj_or_path, train_year_range, test_year_range):
    if isinstance(file_obj_or_path, str):
        df = pd.read_csv(file_obj_or_path, parse_dates=['date'], dayfirst=True)
    else:
        df = pd.read_csv(file_obj_or_path, parse_dates=['date'], dayfirst=True)

    df_train = df[(df['date'].dt.year >= train_year_range[0]) & (df['date'].dt.year <= train_year_range[1])].copy()
    df_test = df[(df['date'].dt.year >= test_year_range[0]) & (df['date'].dt.year <= test_year_range[1])].copy()
     
    # # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°, ‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô, ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°
    # df_train = df_train[df_train['date'].dt.month.isin([8, 9, 10])]
    # df_test = df_test[df_test['date'].dt.month.isin([8, 9, 10])]

    return df_train, df_test

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({'message': 'No file part'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'message': 'No selected file'}), 400

    if file and file.filename.endswith('.csv'):
        file_path = os.path.join(UPLOAD_FOLDER, file.filename)
        file.save(file_path)

        try:
            forecast_days = int(request.form.get('forecastDays'))
            epochs_per_day = json.loads(request.form.get('epochsPerDay'))  # ‚úÖ ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏ä‡πà‡∏ô [50, 50, 50, ...]
            feature_columns = json.loads(request.form.get('featureColumns'))  # ‚úÖ ‡πÄ‡∏ä‡πà‡∏ô ["Rainfall, mm.", "S.3", ...]

            print(forecast_days)
            # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df = pd.read_csv(file_path)
            df = df.dropna().reset_index(drop=True)

            # ‡πÅ‡∏ö‡πà‡∏á 70% train, 30% test
            split_idx = int(len(df) * 0.7)
            df_train = df.iloc[:split_idx].copy()
            df_test = df.iloc[split_idx:].copy()

            # ‚úÖ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
            results = forecast_multiple_days( 
                df_train=df_train,
                df_test=df_test,
                feature_columns=feature_columns,
                forecast_days=forecast_days,
                epochs_per_day=epochs_per_day
            )

            print('////////////////////////////////////////////////////')
            print(results)
            print('////////////////////////////////////////////////////')
            return results
        except Exception as e:
            print("Forecast error:", e)
            return jsonify({'message': 'Processing failed', 'error': str(e)}), 500
    else:
        return jsonify({'message': 'Invalid file type'}), 400


# ‡πÉ‡∏ô Flask ‡∏´‡∏£‡∏∑‡∏≠ FastAPI ‡∏´‡∏£‡∏∑‡∏≠ Django
@app.route('/api/train', methods=['POST'])
def train_model():
    # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...
    results = train_and_forecast()  # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    with open('results/results_day1.json', 'w') as f:
        json.dump(results, f)

    return jsonify({"status": "success", "message": "Training completed."})


@app.route('/api/results', methods=['GET'])
def get_results():
    with open('results/results_day1.json', 'r') as f:
        results = json.load(f)
    return jsonify(results)



# Callback ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch
class CustomCallback(Callback):
    def __init__(self, X_train, Y_train, X_test, Y_test, scaler_inflow, day):
        super().__init__()
        self.X_train = X_train
        self.Y_train = Y_train
        self.X_test = X_test
        self.Y_test = Y_test
        self.scaler_inflow = scaler_inflow
        self.train_rmse = []
        self.test_rmse = []
        self.epoch_rmse_data = []  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RMSE ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch
        self.day = day

    def on_epoch_end(self, epoch, logs=None):
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train
        train_predictions = self.model.predict(self.X_train)
        train_predictions_rescaled = self.scaler_inflow.inverse_transform(train_predictions)
        Y_train_rescaled = self.scaler_inflow.inverse_transform(self.Y_train)
        train_rmse = np.sqrt(mean_squared_error(Y_train_rescaled, train_predictions_rescaled))
        self.train_rmse.append(train_rmse)

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RMSE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test
        test_predictions = self.model.predict(self.X_test)
        test_predictions_rescaled = self.scaler_inflow.inverse_transform(test_predictions)
        Y_test_rescaled = self.scaler_inflow.inverse_transform(self.Y_test)
        test_rmse = np.sqrt(mean_squared_error(Y_test_rescaled, test_predictions_rescaled))
        self.test_rmse.append(test_rmse)

        variable_name = f'epoch_rmse_data_day{self.day}'
        globals()[variable_name] = self.epoch_rmse_data

        self.epoch_rmse_data.append({
            'epoch': epoch + 1,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse
        })

        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ globals() ‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô
        globals()[f'epoch_rmse_data_day{self.day}'] = self.epoch_rmse_data

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• RMSE ‡∏Ç‡∏≠‡∏á train ‡πÅ‡∏•‡∏∞ test ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ epoch
        print(f'Epoch {epoch + 1}: Train RMSE = {train_rmse}, Test RMSE = {test_rmse}')
        print(f"üîç ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {len(self.epoch_rmse_data)} entries")


# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü RMSE ‡∏ï‡πà‡∏≠ Epoch

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Moving Average
def moving_average(data, window_size):
    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü RMSE ‡∏ï‡πà‡∏≠ Epoch
def plot_rmse_vs_epoch(train_rmse, test_rmse, day, window_size=10):
    epochs = np.arange(1, len(train_rmse) + 1)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ window_size ‡πÑ‡∏°‡πà‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    if window_size > len(train_rmse):
        window_size = len(train_rmse)  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error

    # ‡πÉ‡∏ä‡πâ Moving Average
    smoothed_train_rmse = moving_average(train_rmse, window_size)
    smoothed_test_rmse = moving_average(test_rmse, window_size)
    smoothed_epochs = np.arange(1, len(smoothed_train_rmse) + 1)

    plt.figure(figsize=(10, 5))
    plt.plot(smoothed_epochs, smoothed_train_rmse, label='Train RMSE', color='blue', linewidth=2)
    plt.plot(smoothed_epochs, smoothed_test_rmse, label='Test RMSE', color='red', linewidth=2)

    plt.xlabel('Epochs')
    plt.ylabel('RMSE Error')
    plt.title(f'Forecasting {day} day : RMSE Error vs Epochs')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.show()


    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Actual vs Predicted
def plot_comparison(df_train, df_test, train_actual, train_predicted, test_actual, test_predicted, day):
    plt.figure(figsize=(25, 5))

    plt.subplot(1, 4, 2)
    plt.plot(df_train['date'], train_actual, label='Train_Actual', color='blue', linewidth=2)
    plt.plot(df_train['date'], train_predicted, label='Train_Pred', color='red', linestyle='--', linewidth=1.5)
    plt.plot(df_test['date'], test_actual, label='Test_Actual', color='green', linewidth=2)
    plt.plot(df_test['date'], test_predicted, label='Test_Pred', color='orange', linestyle='--', linewidth=1.5)
    plt.title(f'Train Data {day} day: Actual vs Predicted')
    plt.xlabel('Date')
    plt.ylabel('Inflow, cms')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()

    plt.show()

def build_model(input_shape):
    model = Sequential()
    model.add(LSTM(15, return_sequences=True, input_shape=input_shape))
    model.add(LSTM(3, return_sequences=False))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ r, RMSE ‡πÅ‡∏•‡∏∞ NSE
def calculate_metrics(actual, predicted):
    r = np.corrcoef(actual, predicted)[0, 1]
    rmse = np.sqrt(mean_squared_error(actual, predicted))
    nse = 1 - (np.sum((actual - predicted) ** 2) / np.sum((actual - np.mean(actual)) ** 2))
    return r, rmse, nse

# ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô all_graphs
def show_saved_graphs():
    for graph_name, graph in all_graphs.items():
        print(f"Showing graph: {graph_name}")
        plt.figure(graph.number)  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
        plt.show()  # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Dictionary ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô
all_results_train = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train
all_results_test = {}   # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test        

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏±‡∏ô
def forecast_multiple_days(df_train, df_test, feature_columns, forecast_days,epochs_per_day):
    scaler_features = MinMaxScaler(feature_range=(0.05, 0.95))
    scaler_inflow = MinMaxScaler(feature_range=(0.05, 0.95))

    all_results = []

    for day in range(1, forecast_days + 1):
        target_column = f'Inflow, cms+{day}'
        pred_column = f'Pred Inflow, cms+{day}'
        df_train[target_column] = df_train['Inflow, cms'].shift(-day).fillna(method='ffill')
        df_test[target_column] = df_test['Inflow, cms'].shift(-day).fillna(method='ffill')

        if day > 1:
            current_features = feature_columns + [f'Pred Inflow, cms+{i}' for i in range(1, day)]
        else:
            current_features = feature_columns

        X_train, Y_train = df_train[current_features].values, df_train[target_column].values
        X_test, Y_test = df_test[current_features].values, df_test[target_column].values

        X_train_scaled = scaler_features.fit_transform(X_train)
        X_test_scaled = scaler_features.transform(X_test)
        Y_train_scaled = scaler_inflow.fit_transform(Y_train.reshape(-1, 1))
        Y_test_scaled = scaler_inflow.transform(Y_test.reshape(-1, 1))

        X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
        X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

        model = build_model((X_train_reshaped.shape[1], 1))

        # Custom callback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤ RMSE ‡∏Ç‡∏≠‡∏á test
        custom_callback = CustomCallback(X_train_reshaped, Y_train_scaled, 
                                         X_test_reshaped, Y_test_scaled, 
                                         scaler_inflow, day)
        custom_callback.epoch_rmse_data = []

        # ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        history = model.fit(X_train_reshaped, Y_train_scaled, 
                            epochs=epochs_per_day[day-1], 
                            batch_size=512, verbose=1, 
                            callbacks=[custom_callback])

        train_predictions_scaled = model.predict(X_train_reshaped)
        test_predictions_scaled = model.predict(X_test_reshaped)

        train_predictions = scaler_inflow.inverse_transform(train_predictions_scaled)
        test_predictions = scaler_inflow.inverse_transform(test_predictions_scaled)

        df_train[f'Pred Inflow, cms+{day}'] = np.maximum(0, train_predictions.flatten())
        df_test[f'Pred Inflow, cms+{day}'] = np.maximum(0, test_predictions.flatten())

        # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train ‡πÅ‡∏•‡∏∞ Test ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô
        all_results_train[day] = df_train[['date', target_column, pred_column]].copy()
        all_results_test[day] = df_test[['date', target_column, pred_column]].copy()

        print(f"Day {day} prediction stored successfully.")

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        r_train, rmse_train, nse_train = calculate_metrics(df_train[target_column], df_train[f'Pred Inflow, cms+{day}'])
        r_test, rmse_test, nse_test = calculate_metrics(df_test[target_column], df_test[f'Pred Inflow, cms+{day}'])

        print(f"üìä Metrics for Day {day} Forecast:")
        print(f"Train: r = {r_train:.3f}, RMSE = {rmse_train:.3f}, NSE = {nse_train:.3f}")
        print(f"Test:  r = {r_test:.3f}, RMSE = {rmse_test:.3f}, NSE = {nse_test:.3f}")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        results = {
            # f'Metric+{day}': ['r', 'RMSE', 'NSE'],
            # 'Train': [f"{r_train:.2f}", f"{rmse_train:.2f}", f"{nse_train:.2f}"],
            # 'Test': [f"{r_test:.2f}", f"{rmse_test:.2f}", f"{nse_test:.2f}"],
            f'Training+{day}': {
                'R': round(r_train, 2),
                'RMSE': round(rmse_train, 2),
                'NSE': round(nse_train, 2),
                'Data' : df_train
                },
            f'testing+{day}': {
                'R': round(r_test, 2),
                'NSE': round(nse_test, 2),
                'RMSE': round(rmse_test, 2),
                'Data' : df_test
            }
        }

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á dynamic variable ‡∏ä‡∏∑‡πà‡∏≠ results_metrics_day{n}
        # globals()[f'results_metrics_day{day}'] = results

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

        results_df = pd.DataFrame(results[f'n={day}'])
        train_rmse = np.sqrt(history.history['loss'])
        all_results.append(results[f'n={day}'])
        print('-----------------------------------')
        print("Train Predictions:")
        print(df_train[[f'Inflow, cms+{day}',f'Pred Inflow, cms+{day}']].head())
        print('-----------------------------------')
        print("Test Predictions:")
        print(df_test[[f'Inflow, cms+{day}',f'Pred Inflow, cms+{day}']].head())
        print('-----------------------------------')
        print(results_df)
        print('-----------------------------------')

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü RMSE ‡∏ï‡πà‡∏≠ Epoch
        # plot_rmse_vs_epoch(custom_callback.train_rmse, custom_callback.test_rmse, day)
        # plot_comparison(df_train, df_test, Y_train, train_predictions, Y_test, test_predictions, day)

    return all_results

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
if __name__ == '__main__':
    app.run(port=5000, debug=True)
    # forecast_days = 2
    # epochs_per_day = [4, 10, 600, 600, 800, 800, 1000]  # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î epochs ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô

    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    # df_train, df_test = load_data('data/pasak-2014-2023.csv', train_year_range=(2018, 2023), test_year_range=(2014, 2017))
    # feature_columns = ['Rainfall, mm.', 'S.3', 'S.4B', 'S.42', 'S.14', 'Inflow, cms']
    # print(df_train.index)
    # print(df_test.index)
    # print('--------- Train Data ---------')
    # print(df_train.head())
    # print('--------- Test Data ---------')
    # print(df_test.head())

    # forecast_multiple_days(df_train, df_test, feature_columns, forecast_days,epochs_per_day)
    # df_train.to_csv('/content/df_train.csv', index=False)
    # df_test.to_csv('/content/df_test.csv', index=False)

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î RMSE ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô
# for day in range(1, forecast_days + 1):
#     variable_name = f'epoch_rmse_data_day{day}'

#     if variable_name in globals():
#         results_df = pd.DataFrame(globals()[variable_name])

#         print(f"\n========= {variable_name} =========")
#         print(f"üîç ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {len(globals()[variable_name])} entries")  # ‡∏õ‡∏¥‡∏î‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
#         print(results_df)
#         print('-----------------------------------------')
#     else:
#         print(f"\n‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {variable_name}")

# for day in all_results_train.keys():
#     print(f'\n========= Train Data Day {day} =========')
#     print(all_results_train[day].to_string(index=False))  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Train ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô
#     print(f'\n========= Test Data Day {day} =========')
#     print(all_results_test[day].to_string(index=False))   # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡πâ‡∏ô
#     print('-------------------------------------')

# # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô
# for day in range(1, forecast_days + 1):
#     variable_name = f'results_metrics_day{day}'

#     if variable_name in globals():
#         results = globals()[variable_name]
#         results_df = pd.DataFrame(results)

#         print(f"\n========= Metrics for Day {day} =========")
#         print(results_df)
#         print('-----------------------------------------')
#     else:
#         print(f"\n‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Day {day}")